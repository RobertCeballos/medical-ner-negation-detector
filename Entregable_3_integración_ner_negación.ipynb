{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYww3lBlzKI0"
   },
   "source": [
    "# **Entregable 3 - Integración de Modelos NER y Detección de Negación/Incertidumbre para la Extracción Estructurada de Entidades en Historias Clínicas de Cáncer de Mama**\n",
    "\n",
    "**Integrantes:**\n",
    "- Yeraldin Tafur\n",
    "- Mayra Erazo\n",
    "- Roberto Ceballos\n",
    "- Katheryn Sanchez\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://innovacioneducativa.upc.edu.pe/wp-content/uploads/2025/04/dia-mundial-de-la-salud-1170x532.jpg\" width=\"800\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44vlMmIc3cWC"
   },
   "source": [
    "# Introducción\n",
    "\n",
    "En esta entrega se presenta un sistema automático para la extracción estructurada de información clínica relacionada con el cáncer de mama.\n",
    "\n",
    "El sistema integra dos modelos preentrenados de procesamiento de lenguaje natural (PLN):  \n",
    "- Un modelo de **reconocimiento de entidades nombradas (NER)**.  \n",
    "- Un modelo de **detección de negación e incertidumbre**.\n",
    "\n",
    "A partir de historias clínicas en formato texto, se identifican entidades biomédicas relevantes y se clasifica su estado como:\n",
    "- **Afirmativa**\n",
    "- **Negada**\n",
    "- **Sospechosa**\n",
    "\n",
    "Como resultado, se genera un archivo **CSV estructurado** que facilita el análisis clínico y la toma de decisiones basada en datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 103619,
     "status": "ok",
     "timestamp": 1752529155303,
     "user": {
      "displayName": "ROBERTO ARTURO CEBALLOS CEDEÑO",
      "userId": "07993433701421419878"
     },
     "user_tz": 300
    },
    "id": "0aEOlbsV15jI",
    "outputId": "a181e985-b93b-44a8-ea7e-d84b9b454534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.6.0+cu124)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.8.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (1.1.5)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1->transformers[torch])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2025.7.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1->transformers[torch]) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.9)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "# ============ Bloque 1: Instalación de dependencias y autenticación ============\n",
    "\n",
    "# Instalación de las librerías necesarias desde Hugging Face\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate\n",
    "\n",
    "# Instalación de tqdm para mostrar barras de progreso\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytaQaT4_2QrT"
   },
   "outputs": [],
   "source": [
    "# ============ Bloque 2: Autenticación con Hugging Face y montaje de Google Drive ============\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(getpass(\"Introduce tu token de Hugging Face: \")) # Token de acceso personal a Hugging Face..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23237,
     "status": "ok",
     "timestamp": 1751582574295,
     "user": {
      "displayName": "ROBERTO ARTURO CEBALLOS CEDEÑO",
      "userId": "07993433701421419878"
     },
     "user_tz": 300
    },
    "id": "sHZqTLso2O-G",
    "outputId": "d57cedec-8b89-4302-fd35-119f4326324b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# Montar Google Drive para acceder a archivos almacenados\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 78251,
     "status": "ok",
     "timestamp": 1751582655598,
     "user": {
      "displayName": "ROBERTO ARTURO CEBALLOS CEDEÑO",
      "userId": "07993433701421419878"
     },
     "user_tz": 300
    },
    "id": "tFRc4ev0SArB",
    "outputId": "5cc71f74-8e5b-4574-bb05-e9a32ff51725"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-bb46e06c-5c71-437d-9e63-ef844b3df433\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-bb46e06c-5c71-437d-9e63-ef844b3df433\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 54.txt to 54.txt\n",
      "Saving 55.txt to 55.txt\n",
      "Saving 69.txt to 69.txt\n",
      "Saving 100(1).txt to 100(1).txt\n",
      "Saving 100.txt to 100.txt\n",
      "Saving 101.txt to 101.txt\n",
      "Saving 120.txt to 120.txt\n",
      "Saving 121.txt to 121.txt\n",
      "Saving 122.txt to 122.txt\n",
      "Saving 123.txt to 123.txt\n",
      "Saving 124.txt to 124.txt\n",
      "Saving 125.txt to 125.txt\n",
      "Saving 126.txt to 126.txt\n",
      "Saving 127.txt to 127.txt\n",
      "Saving 128.txt to 128.txt\n",
      "Saving 129.txt to 129.txt\n",
      "Saving 130.txt to 130.txt\n",
      "Saving 130m.txt to 130m.txt\n",
      "Saving 131.txt to 131.txt\n",
      "Saving 132.txt to 132.txt\n",
      "Saving 133.txt to 133.txt\n",
      "Saving 134.txt to 134.txt\n",
      "Saving 135.txt to 135.txt\n",
      "Saving 136.txt to 136.txt\n",
      "Saving 137.txt to 137.txt\n",
      "Saving 138.txt to 138.txt\n",
      "Saving 139.txt to 139.txt\n",
      "Saving 140.txt to 140.txt\n",
      "Saving 141.txt to 141.txt\n",
      "Saving 142.txt to 142.txt\n",
      "Saving 143.txt to 143.txt\n",
      "Saving 144.txt to 144.txt\n",
      "Saving 145.txt to 145.txt\n",
      "Saving 146.txt to 146.txt\n",
      "Saving 147.txt to 147.txt\n",
      "Saving 148.txt to 148.txt\n",
      "Saving 149.txt to 149.txt\n",
      "Saving 150.txt to 150.txt\n",
      "Saving 151.txt to 151.txt\n",
      "Saving 152.txt to 152.txt\n",
      "Saving 153.txt to 153.txt\n",
      "Saving 154.txt to 154.txt\n",
      "Saving 155.txt to 155.txt\n",
      "Saving 156.txt to 156.txt\n",
      "Saving 157.txt to 157.txt\n",
      "Saving 158.txt to 158.txt\n",
      "Saving 159.txt to 159.txt\n",
      "Saving 160.txt to 160.txt\n",
      "Saving 161.txt to 161.txt\n",
      "Saving 162.txt to 162.txt\n",
      "Saving 163.txt to 163.txt\n",
      "Saving 233.txt to 233.txt\n",
      "Saving 234.txt to 234.txt\n",
      "Saving 235.txt to 235.txt\n",
      "Saving 236.txt to 236.txt\n",
      "Saving 237.txt to 237.txt\n",
      "Saving 238.txt to 238.txt\n",
      "Saving 239.txt to 239.txt\n",
      "Saving 240.txt to 240.txt\n",
      "Saving 241.txt to 241.txt\n",
      "Saving 1134.txt to 1134.txt\n",
      "Saving 1521.txt to 1521.txt\n",
      "Saving 1525.txt to 1525.txt\n",
      "Saving 1567.txt to 1567.txt\n",
      "Saving 1710.txt to 1710.txt\n",
      "Saving 2102.txt to 2102.txt\n",
      "Saving 2305.txt to 2305.txt\n",
      "Saving 2501.txt to 2501.txt\n",
      "Saving 2567.txt to 2567.txt\n",
      "Saving 2759.txt to 2759.txt\n",
      "Saving 3314.txt to 3314.txt\n",
      "Saving 3389.txt to 3389.txt\n",
      "Saving 3391.txt to 3391.txt\n",
      "Saving 4512.txt to 4512.txt\n",
      "Saving 5514.txt to 5514.txt\n",
      "Saving 5547.txt to 5547.txt\n",
      "Saving 5805.txt to 5805.txt\n",
      "Saving 7002.txt to 7002.txt\n",
      "Saving 7754.txt to 7754.txt\n",
      "Saving 9419.txt to 9419.txt\n",
      "Saving 9433.txt to 9433.txt\n",
      "Saving 13734.txt to 13734.txt\n",
      "Saving 36127.txt to 36127.txt\n",
      "Saving 36687.txt to 36687.txt\n",
      "Saving 37139.txt to 37139.txt\n",
      "Saving 45812.txt to 45812.txt\n",
      "Saving 212155.txt to 212155.txt\n",
      "Saving 242186_1.txt to 242186_1.txt\n",
      "Saving 261062.txt to 261062.txt\n",
      "Saving 330177_1.txt to 330177_1.txt\n",
      "Saving 499061.txt to 499061.txt\n",
      "Saving 553284.txt to 553284.txt\n",
      "Saving 569236.txt to 569236.txt\n",
      "Saving 814012.txt to 814012.txt\n",
      "Saving 912866.txt to 912866.txt\n",
      "Saving 1010408.txt to 1010408.txt\n",
      "Saving 1081698.txt to 1081698.txt\n",
      "Saving 1099899.txt to 1099899.txt\n",
      "Saving 1126737.txt to 1126737.txt\n",
      "Saving 1234567m.txt to 1234567m.txt\n",
      "Saving 1365655.txt to 1365655.txt\n",
      "Saving 2060668.txt to 2060668.txt\n",
      "Saving 2071255.txt to 2071255.txt\n",
      "Saving 2720211.txt to 2720211.txt\n",
      "Saving 5692361.txt to 5692361.txt\n",
      "Saving 8140123m.txt to 8140123m.txt\n",
      "Archivo subido: 54.txt\n",
      "Archivo subido: 55.txt\n",
      "Archivo subido: 69.txt\n",
      "Archivo subido: 100(1).txt\n",
      "Archivo subido: 100.txt\n",
      "Archivo subido: 101.txt\n",
      "Archivo subido: 120.txt\n",
      "Archivo subido: 121.txt\n",
      "Archivo subido: 122.txt\n",
      "Archivo subido: 123.txt\n",
      "Archivo subido: 124.txt\n",
      "Archivo subido: 125.txt\n",
      "Archivo subido: 126.txt\n",
      "Archivo subido: 127.txt\n",
      "Archivo subido: 128.txt\n",
      "Archivo subido: 129.txt\n",
      "Archivo subido: 130.txt\n",
      "Archivo subido: 130m.txt\n",
      "Archivo subido: 131.txt\n",
      "Archivo subido: 132.txt\n",
      "Archivo subido: 133.txt\n",
      "Archivo subido: 134.txt\n",
      "Archivo subido: 135.txt\n",
      "Archivo subido: 136.txt\n",
      "Archivo subido: 137.txt\n",
      "Archivo subido: 138.txt\n",
      "Archivo subido: 139.txt\n",
      "Archivo subido: 140.txt\n",
      "Archivo subido: 141.txt\n",
      "Archivo subido: 142.txt\n",
      "Archivo subido: 143.txt\n",
      "Archivo subido: 144.txt\n",
      "Archivo subido: 145.txt\n",
      "Archivo subido: 146.txt\n",
      "Archivo subido: 147.txt\n",
      "Archivo subido: 148.txt\n",
      "Archivo subido: 149.txt\n",
      "Archivo subido: 150.txt\n",
      "Archivo subido: 151.txt\n",
      "Archivo subido: 152.txt\n",
      "Archivo subido: 153.txt\n",
      "Archivo subido: 154.txt\n",
      "Archivo subido: 155.txt\n",
      "Archivo subido: 156.txt\n",
      "Archivo subido: 157.txt\n",
      "Archivo subido: 158.txt\n",
      "Archivo subido: 159.txt\n",
      "Archivo subido: 160.txt\n",
      "Archivo subido: 161.txt\n",
      "Archivo subido: 162.txt\n",
      "Archivo subido: 163.txt\n",
      "Archivo subido: 233.txt\n",
      "Archivo subido: 234.txt\n",
      "Archivo subido: 235.txt\n",
      "Archivo subido: 236.txt\n",
      "Archivo subido: 237.txt\n",
      "Archivo subido: 238.txt\n",
      "Archivo subido: 239.txt\n",
      "Archivo subido: 240.txt\n",
      "Archivo subido: 241.txt\n",
      "Archivo subido: 1134.txt\n",
      "Archivo subido: 1521.txt\n",
      "Archivo subido: 1525.txt\n",
      "Archivo subido: 1567.txt\n",
      "Archivo subido: 1710.txt\n",
      "Archivo subido: 2102.txt\n",
      "Archivo subido: 2305.txt\n",
      "Archivo subido: 2501.txt\n",
      "Archivo subido: 2567.txt\n",
      "Archivo subido: 2759.txt\n",
      "Archivo subido: 3314.txt\n",
      "Archivo subido: 3389.txt\n",
      "Archivo subido: 3391.txt\n",
      "Archivo subido: 4512.txt\n",
      "Archivo subido: 5514.txt\n",
      "Archivo subido: 5547.txt\n",
      "Archivo subido: 5805.txt\n",
      "Archivo subido: 7002.txt\n",
      "Archivo subido: 7754.txt\n",
      "Archivo subido: 9419.txt\n",
      "Archivo subido: 9433.txt\n",
      "Archivo subido: 13734.txt\n",
      "Archivo subido: 36127.txt\n",
      "Archivo subido: 36687.txt\n",
      "Archivo subido: 37139.txt\n",
      "Archivo subido: 45812.txt\n",
      "Archivo subido: 212155.txt\n",
      "Archivo subido: 242186_1.txt\n",
      "Archivo subido: 261062.txt\n",
      "Archivo subido: 330177_1.txt\n",
      "Archivo subido: 499061.txt\n",
      "Archivo subido: 553284.txt\n",
      "Archivo subido: 569236.txt\n",
      "Archivo subido: 814012.txt\n",
      "Archivo subido: 912866.txt\n",
      "Archivo subido: 1010408.txt\n",
      "Archivo subido: 1081698.txt\n",
      "Archivo subido: 1099899.txt\n",
      "Archivo subido: 1126737.txt\n",
      "Archivo subido: 1234567m.txt\n",
      "Archivo subido: 1365655.txt\n",
      "Archivo subido: 2060668.txt\n",
      "Archivo subido: 2071255.txt\n",
      "Archivo subido: 2720211.txt\n",
      "Archivo subido: 5692361.txt\n",
      "Archivo subido: 8140123m.txt\n",
      "Total oraciones cargadas: 1310\n",
      "Ejemplo de oración: Mujer de 40 años diagnosticada con cancer de mama que acude a revisión.\n"
     ]
    }
   ],
   "source": [
    "# ============ Bloque 3: Carga de historias clínicas desde archivos .txt ============\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "# Permite al usuario subir archivos .txt desde su máquina local\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Ver nombres de los archivos subidos\n",
    "all_frases_df = []\n",
    "for file_name in uploaded.keys():\n",
    "    print(f\"Archivo subido: {file_name}\")\n",
    "\n",
    "    # Leer el contenido del archivo\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        lines = [line.strip() for line in file if line.strip()]\n",
    "        all_frases_df.extend(lines)\n",
    "\n",
    "print(f\"Total oraciones cargadas: {len(all_frases_df)}\")\n",
    "print(\"Ejemplo de oración:\", all_frases_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMwfGcL1yxBJ"
   },
   "source": [
    "Cargamos modelo de cancer de mama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48109,
     "status": "ok",
     "timestamp": 1751584920148,
     "user": {
      "displayName": "ROBERTO ARTURO CEBALLOS CEDEÑO",
      "userId": "07993433701421419878"
     },
     "user_tz": 300
    },
    "id": "LuYrJMgQVFRT",
    "outputId": "0a3932f6-ded4-49f9-ccb7-c135d23d1b71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1310/1310 [00:39<00:00, 32.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV generado con éxito.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============ Bloque 4: Diccionarios de etiquetas ============\n",
    "\n",
    "# Diccionario que mapea los índices a etiquetas del modelo NER biomédico\n",
    "id2label_ner = {\n",
    "    0: \"B-AGE\", 1: \"B-STAGE\", 2: \"B-DATE\", 3: \"B-IMPLICIT_DATE\", 4: \"B-TNM\",\n",
    "    5: \"B-FAMILY\", 6: \"B-OCURRENCE_EVENT\", 7: \"B-TOXIC_HABITS\", 8: \"B-HABIT-QUANTITY\",\n",
    "    9: \"B-TREATMENT_NAME\", 10: \"B-LINE_CICLE_NUMBER\", 11: \"B-SURGERY\", 12: \"B-DRUG\",\n",
    "    13: \"B-DOSE\", 14: \"B-FREQ\", 15: \"B-BIOMARKER\", 16: \"B-CLINICAL_SERVICE\",\n",
    "    17: \"B-COMORBIDITY\", 18: \"B-PROGRESION\", 19: \"B-GINECOLOGICAL_HISTORY\",\n",
    "    20: \"B-GINE_OBSTETRICS\", 21: \"B-ALLERGIES\", 22: \"B-DURATION\",\n",
    "    23: \"I-AGE\", 24: \"I-STAGE\", 25: \"I-DATE\", 26: \"I-IMPLICIT_DATE\",\n",
    "    27: \"I-TNM\", 28: \"I-FAMILY\", 29: \"I-OCURRENCE_EVENT\", 30: \"I-TOXIC_HABITS\",\n",
    "    31: \"I-HABIT-QUANTITY\", 32: \"I-TREATMENT_NAME\", 33: \"I-LINE_CICLE_NUMBER\",\n",
    "    34: \"I-SURGERY\", 35: \"I-DRUG\", 36: \"I-DOSE\", 37: \"I-FREQ\", 38: \"I-BIOMARKER\",\n",
    "    39: \"I-CLINICAL_SERVICE\", 40: \"I-COMORBIDITY\", 41: \"I-PROGRESION\",\n",
    "    42: \"I-GINECOLOGICAL_HISTORY\", 43: \"I-GINE_OBSTETRICS\", 44: \"I-ALLERGIES\",\n",
    "    45: \"I-DURATION\", 46: \"B-CANCER_CONCEPT\", 47: \"I-CANCER_CONCEPT\", 48: \"O\"\n",
    "}\n",
    "label2id_ner = {v: k for k, v in id2label_ner.items()}\n",
    "\n",
    "# Diccionario para las etiquetas del modelo de Negación/Incertidumbre\n",
    "id2label_neg = {\n",
    "    0: \"B-NEG\", 1: \"B-NSCO\", 2: \"B-UNC\", 3: \"B-USCO\", 4: \"I-NEG\",\n",
    "    5: \"I-NSCO\", 6: \"I-UNC\", 7: \"I-USCO\", 8: \"O\"\n",
    "}\n",
    "label2id_neg = {v: k for k, v in id2label_neg.items()}\n",
    "\n",
    "# ============ Bloque 5: Carga de modelos y tokenizadores ============\n",
    "\n",
    "# Cargar el modelo NER desde Hugging Face\n",
    "model_ner = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"anvorja/breast-cancer-biomedical-ner-sp-1\",\n",
    "    id2label=id2label_ner,\n",
    "    label2id=label2id_ner\n",
    ")\n",
    "tokenizer_ner = AutoTokenizer.from_pretrained(\"anvorja/breast-cancer-biomedical-ner-sp-1\", use_fast=True)\n",
    "\n",
    "# Cargar el modelo de detección de negación/uncertainty\n",
    "model_neg = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"JuanSolarte99/bert-base-uncased-finetuned-ner-negation_detection_NUBES\",\n",
    "    id2label=id2label_neg,\n",
    "    label2id=label2id_neg\n",
    ")\n",
    "tokenizer_neg = AutoTokenizer.from_pretrained(\"JuanSolarte99/bert-base-uncased-finetuned-ner-negation_detection_NUBES\", use_fast=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ner.to(device)\n",
    "model_neg.to(device)\n",
    "\n",
    "# ============ Bloque 6: Determinación del estado de las entidades (Negada, Sospechosa, Afirmativa) ============\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for idx, sentence in enumerate(tqdm(all_frases_df)):\n",
    "    enc_ner = tokenizer_ner(sentence, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    enc_neg = tokenizer_neg(sentence, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_ner = model_ner(**enc_ner).logits\n",
    "        logits_neg = model_neg(**enc_neg).logits\n",
    "\n",
    "    pred_ner = torch.argmax(logits_ner, dim=-1)[0].tolist()\n",
    "    pred_neg = torch.argmax(logits_neg, dim=-1)[0].tolist()\n",
    "\n",
    "    tokens_ner = tokenizer_ner.convert_ids_to_tokens(enc_ner[\"input_ids\"][0])\n",
    "    word_ids_ner = enc_ner.word_ids(batch_index=0)\n",
    "    word_ids_neg = enc_neg.word_ids(batch_index=0)\n",
    "\n",
    "    entidades = []\n",
    "    entidad_actual = \"\"\n",
    "    etiqueta_actual = \"\"\n",
    "    indices_entidad = []\n",
    "\n",
    "    for i, (token, label_id, word_id) in enumerate(zip(tokens_ner, pred_ner, word_ids_ner)):\n",
    "        if word_id is None:\n",
    "            continue\n",
    "        label = id2label_ner[label_id]\n",
    "        if label.startswith(\"B-\"):\n",
    "            if entidad_actual:\n",
    "                entidades.append((entidad_actual.strip(), etiqueta_actual, indices_entidad))\n",
    "            entidad_actual = token.replace(\"▁\", \"\").replace(\"##\", \"\")\n",
    "            etiqueta_actual = label[2:]\n",
    "            indices_entidad = [i]\n",
    "        elif label.startswith(\"I-\") and etiqueta_actual == label[2:]:\n",
    "            entidad_actual += \" \" + token.replace(\"▁\", \"\").replace(\"##\", \"\")\n",
    "            indices_entidad.append(i)\n",
    "        else:\n",
    "            if entidad_actual:\n",
    "                entidades.append((entidad_actual.strip(), etiqueta_actual, indices_entidad))\n",
    "            entidad_actual = \"\"\n",
    "            etiqueta_actual = \"\"\n",
    "            indices_entidad = []\n",
    "\n",
    "    if entidad_actual:\n",
    "        entidades.append((entidad_actual.strip(), etiqueta_actual, indices_entidad))\n",
    "\n",
    "    for entidad, etiqueta, indices in entidades:\n",
    "        estados_detectados = set()\n",
    "        for i in indices:\n",
    "            if i < len(pred_neg):\n",
    "                etiqueta_neg = id2label_neg.get(pred_neg[i], \"O\")\n",
    "                if \"NEG\" in etiqueta_neg:\n",
    "                    estados_detectados.add(\"Negada\")\n",
    "                elif \"UNC\" in etiqueta_neg or \"USCO\" in etiqueta_neg:\n",
    "                    estados_detectados.add(\"Sospechosa\")\n",
    "\n",
    "        if \"Negada\" in estados_detectados:\n",
    "            estado_final = \"Negada\"\n",
    "        elif \"Sospechosa\" in estados_detectados:\n",
    "            estado_final = \"Sospechosa\"\n",
    "        else:\n",
    "            estado_final = \"Afirmativa\"\n",
    "\n",
    "        resultados.append({\n",
    "            \"patient_id\": idx,\n",
    "            \"sentence\": sentence,\n",
    "            \"NER\": etiqueta,\n",
    "            \"Estado\": estado_final\n",
    "        })\n",
    "\n",
    "# ============ Bloque 7: Construcción del DataFrame y exportación a CSV ============\n",
    "\n",
    "df_resultado = pd.DataFrame(resultados)\n",
    "df_resultado.to_csv(\"resultado_entidades.csv\", index=False)\n",
    "print(\"Archivo CSV generado con éxito.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
